# 真实面经案例集锦

## 📚 使用说明
- 本文收集了各大公司的真实面经案例
- 保留了完整的面试轮次和问题上下文
- 建议先通过分类题库学习,再结合真实案例模拟练习

---

## 案例1:某公司大模型算法岗

### 一面
1. 请介绍 Transformer 的结构组成及各部分作用
2. 如何降低 Transformer 的计算复杂度?常见的稀疏注意力变体有哪些?
3. LoRA微调的原理是什么?秩 r 的选择会对模型表现产生什么影响?
4. kv cache是什么?为什么能极大地提升推理速度?
5. RAG的完整流程,构建向量检索库时如何处理时间衰减对召回的影响?
6. 微调时的训练数据是怎么构建的?如何保证样本多样性和质量?
7. 在 RAG+知识图谱的 Agent 系统中,知识图谱更新的机制是怎样的?是怎样保证实时性的?
8. 训练 LoRA 模型时,你是如何选择冻结层的?依据是什么?
9. 在高并发查询 Agent 系统中,你会如何优化召回和生成阶段的延迟?
10. 大规模 Agent 系统在多线程/多进程场景下的资源调度策略如何设计?
11. 如果你要在 GPU 资源有限的条件下同时提供推理和微调服务,如何做资源分配和任务调度以保证时延和吞吐?
12. 代码:lc15 三数之和

### 二面
1. 介绍下self-attention,计算其时间复杂度
2. 为什么要用multi-head attention?
3. PPO的clip机制?在线强化学习和离线强化学习有什么区别?RLHF是哪一种?
4. 为什么要用reference model? 为了解决什么问题?
5. 如何让多个agent协同工作的?举个具体的协同机制例子
6. 如果一个agent误判导致策略冲突,如何处理?
7. 有没有用到类似AutoGen或LangChain的框架?为什么选这个框架?
8. 你是怎么设计agent的记忆系统?
9. 长期记忆如何存储?如果历史记录量非常大,怎么优化查询效率?
10. 有没有做记忆衰退,避免旧数据干扰新任务?
11. 你们这种模块堆叠的架构是怎么设计视觉问答模块和动作模块的协同逻辑的?
12. human feedback是怎么被agent消化吸收的?有没有用rl进行策略更新?
13. 有没有做过模型压缩?比如在车载端或低端设备上的推理加速?
14. 如果量化后理解能力下降怎么办?怎么做精度补偿?
15. 你怎么处理响应速度与推理精度之间的tradeoff?是先召回再精排,还是单次生成?
16. 如果要做电商agent,你会选择哪些模态的信息作为输入?比如文本评论、图像、视频、购买记录?

---

## 案例2:某公司强化学习方向

### 一面
1. PPO的原理?从维护的四个model讲,再详细讲一下训练流程和损失函数各个参数含义?
2. 为什么有了reward model还需要critic model?critic model作用是什么?
3. 交叉熵和kl散度的联系和区别?PPO的kl散度可以改成交叉熵吗?分类任务可以用KL散度吗?
4. GRPO的kl散度和PPO的kl散度区别?K1 K2 K3估计区别?
5. rollout数量 batchsize数量和计算资源(卡的数量)有什么关系?线性?非线性?
6. 真实采样数量一定等于rollout数量吗?
7. 提到了拒绝采样,详细讲一下
8. 你是怎么设计agent的记忆系统?
9. 长期记忆如何存储?如果历史记录量非常大,怎么优化查询效率?
10. 你们有没有用到类似AutoGen或LangChain的框架?为什么选这个框架?
11. vLLM框架是怎么做推理加速的?

### 二面
1. 你的 Agent 系统Prompt 是怎么设计和迭代的?有没有做过 Prompt 自动优化?当用户提出不完整的请求时,如何补全用户意图的?
2. 构建 Agent 的时候,遇到过哪些瓶颈?LangChain 的 memory 默认机制在多用户并发中怎么做隔离?你是如何保证线程安全的?
3. 微调 Llama2 你是怎么选择训练样本的?清洗逻辑是什么?你有没有观察到哪些训练样本质量问题对模型行为有很大影响?举例说明
4. DPO相比 SFT,有哪些优劣?它在 Agent 任务上效果提升明显吗?你怎么构造偏好对?构造逻辑是自动的还是人工?
5. 你说你服务部署在 vLLM 上,为何选择它?KV-cache 如何帮助推理加速?你自己做过哪些优化?
6. 假如需要支持 Streaming 输出,但当前服务延迟又超标,你会怎么折中设计?
7. 多轮对话上下文状态管理是如何做的?如何在高并发场景下保证一致性?
8. 你做的 Agent 使用了多少个外部工具,在调用链条上如何保障故障容错和超时机制?
9. 有没有做过工具调用失败后的feedback策略设计?
10. 训练过程中数据来自用户行为日志,你是如何从这些数据中抽取训练对话的?有没有做过归一化或事件抽象?
11. 有没有了解过带有时间窗口/偏移限制的对话系统?模型怎么"理解时间"?

---

## 案例3:美团北斗大模型校招

### 第一轮面试
1. 八股:LoRA 微调原理?训练时调过哪些超参数?有什么经验?
2. 八股:SFT 的 loss 如何只计算回答部分?(如何 ignore padding token?)
3. 八股:Attention 计算中有哪些显存优化策略?(如 KV Cache 复用、batch 拼接)
4. 八股:分布式训练中 Zero-2 和 Zero-3 的核心区别是什么?
5. 八股:Transformer 为什么用 LayerNorm 而不是 BatchNorm?
6. 项目:项目中的数据规模多大?SFT 数据是如何清洗和构建的?
7. 项目:为什么在项目中选择 GRPO 而不是 PPO 或 DPO?它解决了什么问题?
8. 项目:奖励函数是如何设计的?是否考虑了事实正确性、安全性等维度?
9. 项目:为什么引入 RAG?在什么场景下 RAG 比纯 SFT 更有效?
10. 项目:用 LangGraph 实现多轮对话 Agent,相比手写 prompt 流程有哪些工程和效果优势?
11. 代码题:lc102 二叉树的层序遍历

### 第二轮面试
1. 八股:bf16 和 float16 的区别?各占多少位?训练中如何选择?
2. 八股:DeepSpeed Zero 各阶段分别做了哪些优化?
3. 八股:如何估算 LLaMA-7B 模型推理时的显存占用?
4. 八股:Prefix LM、Causal LM、Encoder-Decoder 三类架构的适用场景与优缺点?
5. 八股:Qwen 或 DeepSeek 技术报告中提到的关键创新点有哪些?(如 RoPE 外推、MoE)
6. 项目:PPO/GRPO 微调后,如何防止模型在分布外(OOD)问题上性能崩塌?
7. 项目:是否自己实现过 RLHF 流程?不用框架能否手写 PPO 核心逻辑?
8. 项目:模型部署用了什么框架(vLLM/TGI/自研)?如何优化推理延迟和吞吐?
9. 项目:未来希望专注大模型哪个方向?(对齐 / 推理加速 / 长上下文?)为什么?
10. 代码题:LeetCode 25:K 个一组翻转链表

---

## 案例4:字节跳动多模态算法岗

### 第一轮面试

**基础八股**
1. 多模态学习中常见的融合方式有哪些?早期融合 vs 晚期融合 vs 中间融合的区别和适用场景?
2. CLIP 模型的原理是什么?它是如何实现图文对齐的?损失函数怎么设计的?
3. Vision Transformer (ViT) 和 CNN 在图像特征提取上的优劣对比?
4. 什么是对比学习(Contrastive Learning)?InfoNCE loss 的公式和作用?
5. 大模型训练中常用的优化器有哪些?AdamW 和 Adam 的区别是什么?

**项目深挖**
6. 请详细介绍你简历中提到的多模态项目:输入是什么?模型结构?如何对齐不同模态?
7. 项目中遇到的最大挑战是什么?你是如何解决模态异构性问题的?
8. 有没有做过消融实验?哪些模块对最终性能提升最关键?
9. 如果让你将该项目部署上线,你会考虑哪些工程优化点?(如推理加速、缓存策略等)
10. 你的模型在训练集上表现很好,但在新场景(如不同光照/语言风格)下性能下降明显,你会如何提升泛化能力?

**LeetCode**
11. LeetCode 300:最长递增子序列——要求写出 O(n log n) 解法

### 第二轮面试

**基础八股**
1. 大模型训练中的数据并行、模型并行、流水线并行分别适用于什么场景?ZeRO 是什么?
2. 如何评估多模态模型的性能?除了准确率,还有哪些指标?(如 Recall@K, mAP 等)
3. 什么是 instruction tuning?在多模态场景下如何做?
4. BLIP / BLIP-2 的核心创新点是什么?和 Flamingo 有什么区别?

---

## 案例5:某公司 Agent 方向深度面试

### 一面
1. 和传统SFT相比,RLHF旨在解决语言模型中的哪些核心问题?
2. 在Agent的设计中,"规划能力"至关重要。请谈谈目前有哪些主流方法可以赋予LLM规划能力?(例如CoT, ToT, GoT)
3. 什么是多智能体系统?让多个LLM Agent协同工作相比于单个Agent有什么优势?又会引入哪些新的复杂性?
4. 你用过哪些Agent框架?选型是如何选的?你最终场景的评价指标是什么?
5. 你简历中的客服Agent项目,是如何判断用户意图是否需要调用外部API的?用了分类模型还是prompt判断?
6. 大模型生成工具调用时,如何避免参数格式错误?有哪些后处理或约束解码方法?
7. 当多个工具都能完成子任务时,你的Agent如何做选择?有没有引入打分或排序模块?
8. 在Agent中引入"记忆"机制时,为什么常用向量数据库?如何设计embedding和检索策略?
9. 项目上线后,你是如何收集bad case并迭代模型/策略的?有做在线学习吗?

### 二面
1. 比较一下几种常见的LLM架构,例如Encoder-Only, Decoder-Only 和 Encoder-Decoder,并说明它们各自最擅长的任务类型
2. ReAct框架的核心思想是什么?为什么它比纯prompting在复杂任务上表现更好?
3. Function Calling 和 Toolformer 的本质区别是什么?各自在训练/推理阶段如何工作?
4. 如果让你设计一个能行程规划的旅行Agent,你会如何拆解任务?各子Agent职责怎么划分?
5. 你的Agent如何处理工具调用失败(如API超时、返回空)?有设计重试、降级或用户澄清机制吗?
6. 在真实场景中,如何防止Agent泄露用户隐私或越权操作?从算法和系统层面谈谈你的设计
7. 如果用户连续追问"为什么选这家酒店?",Agent如何回溯决策链并给出可解释理由?
8. 如何评估一个Agent系统的鲁棒性?除了准确率,还会测试哪些对抗性或边缘case?

---

## 案例6:大厂通用 LLM 算法岗

### 一面
1. 自我介绍(建议控制在2分钟内,突出与大模型相关的经历)
2. 高频八股:大语言模型中的注意力机制?多头 vs 单头优势在哪?
3. 易混淆点:LayerNorm和BatchNorm在训练时的梯度计算区别?
4. 架构对比:当前主流LLM(如 Llama、Qwen、ChatGLM)在架构设计上有何异同?
5. Prompt工程:如何设计有效的提示词?有哪些实用技巧?
6. 微调重点:LoRA是什么?原理 & 为什么它能高效微调大模型?
7. RLHF必问:RLHF训练流程?存在哪些潜在风险(比如奖励黑客、过拟合等)?
8. 幻觉问题:大模型"胡说八道"的原因?有哪些缓解策略?
9. In-Context Learning:Zero-Shot/Few-Shot 的应用场景 & 局限性?
10. 评估方法论:如何科学评估大模型性能?评估数据集怎么构造才靠谱?
11. 代码题:lc 岛屿数量(DFS/BFS 都要会!)

### 二面
1. 自我介绍(面试官会结合简历追问细节!)
2. 计算优化:KV Cache 的内存瓶颈?推导多头注意力的时间/空间复杂度
3. 底层细节:Tokenization 是如何工作的?BPE、WordPiece 有啥区别?
4. 模型压缩:知识蒸馏在大模型压缩中的应用?效果如何?
5. 项目深挖:你用过 Qwen?说说它的特点和优势(MoE?位置编码?训练数据?)
6. 训练调参:微调 Qwen 时验证集 loss震荡,可能原因有哪些?(学习率?数据噪声?)
7. 参数量计算:Qwen-14B 的 "14B" 怎么算出来的?推理时FLOPs大概多少?
8. 显存优化:训练/推理显存不够?有哪些实用trick?(量化、Offload、FlashAttention…)
9. 前沿趋势:聊聊 LLM 未来方向?多模态模型(如 Qwen-VL)如何融合图文信息?
10. 代码题:lc最大乘积子数组(动态规划经典题,注意负负得正!)

---

## 案例7:大厂 Agent 开发岗

### 一面
1. 八股:Encoder与decoder的中Attention区别?
2. 八股:Attention如何计算?为什么除以根号下Dk?mask attention是如何实现的?
3. 八股:除了MHA还知道哪些(GQA MQA MLA)讲原理
4. 八股:为什么要用位置编码?为什么要用sin_cos?
5. 项目:问之前实习的Agent的设计逻辑,问创新方法的实现
6. 项目:你提到用DeepSpeed做SFT训练,请讲一下DeepSpeed ZeRO Stage 1-3的区别,以及什么时候用FSDP会更好?
7. 项目:问Agent的工具tool的设计,是否是workflow形式
8. 项目:了解哪些agent开发框架,例如langchain和LlamaIndex,他们核心应用场景有何不同
9. 项目:问数据的输入输出格式如何保证大模型输出稳定的json做了哪些工作
10. 智力题:有12个外观相同的芯片、其中一个重量不同(不知轻重),用天平最少称几次能找出这张芯片?
11. 代码题:lc215 数组中的第K个最大元素

### 二面
1. 八股:请介绍一下Transformer的核心组件及其作用
2. 八股:介绍LLM Decoder-Only架构
3. 八股:你对SFT的理解是什么?与预训练相比有什么差异?
4. 项目:SFT冷启动时数据集构造需要注意哪些因素?为什么要做数据清洗与均衡采样?
5. 项目:介绍一下RAG的整体流程。在Agent落地场景中,RAG会遇到哪些延迟和正确率问题?你怎么优化召回链路?
6. 项目:在你的问答Agent项目中,数据集构造的自动化流程是怎么实现的?
7. 项目:你是如何利用多Agent协同来提高推理正确率的?调度策略如何实现?
8. 项目:你提到用DeepSpeed做SFT训练,请讲一下DeepSpeed ZeRO Stage 1-3的区别,以及什么时候用FSDP会更好?
9. 项目:你做Prompt优化时,是如何判断优化后的Prompt在Agent推理链路中性能提升的?用什么指标来衡量?
10. 项目:在多Agent系统中,如何保证异步任务执行的稳定性和结果一致性?
11. 项目:如果Agent推理API需要低延迟响应,你会从哪些方面做系统级优化?

---

## 案例8:美团大模型应用算法工程师

### 一面
1. 自我介绍
2. 八股:NLP和LLM最大的区别是什么?两者有何共同和不同之处?
3. 八股:激活函数有了解吗,你知道哪些LLM常用的激活函数?为什么选用它?
4. 八股:开源框架了解过哪些?Qwen,Deepseek的论文是否有研读过,说一下其中的创新点主要体现在哪?
5. 项目:介绍微调负责的工作,大模型微调最重要的是什么?
6. 项目:SFT+DPO训练怎么组织这部分数据的?是自己构造还是用公开数据?
7. 项目:看你做过LoRA微调,那你是怎么选rank值?合并adapter权重的时候有没有遇到梯度爆炸?
8. 项目:说下LoRA的原理,LoRA是不是只能在Linear层插?为什么不能插在LayerNorm之后?这会对训练稳定性造成什么影响
9. 项目:刚才提到用过QLoRA,能具体说说QLoRA是怎么降低资源成本吗?
10. 项目:llm推理效率,如果真的部署到在线系统里,这个效率的问题怎么解决呢
11. 项目:有没有尝试过模型裁剪?比如 low-rank adaptor、LoRA 融合,或者用Mamba替换部分token path?
12. 代码题:实现Casual mask的MHA,说下计算复杂度

### 二面
1. 自我介绍
2. 八股:Transformer底层原理,为啥能替代RNN
3. 八股:大模型预测token的损失是怎么算的?有哪几种常见的损失函数?
4. 项目:看你做过RAG,讲讲从数据清洗到检索服务上线这整个链路是怎么搭的,怎么做chunk切分的
5. 项目:你觉得当前RAG的最大瓶颈在哪?你做过哪些改进来提升Recall
6. 项目:传统RAG有什么痛点;介绍GraphRAG,GraphRAG的难点是什么;GraphRAG如何应对增量场景
7. 项目:RAG中知识库搭建,对知识库的文件文档进行动态增量更新,怎么来避免新旧文档的文单的分布不一致导致的这种检索偏差问题
8. 项目:RAG怎么评估,RAG评估体系中最重要的是什么
9. 项目:常见的量化方式有哪些,QLoRA为什么选的是NF4和FP16这组组合,而不是别的组合?你能说说NF4的分布拟合逻辑吗
10. 项目:模型部署相关,说下模型部署的参数量和需求硬件之间的关系
11. 项目:部署一个MOE架构的千分三的235b的一个模型,他所需要的算力大概是多少?
12. 代码题:lc54. 螺旋矩阵

---

## 案例9:某大厂 RAG 专项面试

### 一面
1. 八股:介绍几种Attention(MHA,MQA,GQA)的区别
2. 八股:分别讲一下Dense模型和MoE模型以及二者的区别
3. 八股:讲一下MoE的路由机制是如何做的?
4. 项目:介绍RAG项目,讲一下RAG项目的亮点
5. 项目:如果召回的答案不是想要的,该怎么处理?
6. 项目:讲一下BM25算法原理
7. 项目:是否做过意图识别?如果要做意图识别,可以怎么实现?
8. 项目:微调项目是如何模型选型
9. 项目:如何做微调的?直接用 PEFT 库,还是用LLama Factory做的?
10. 项目:讲一下DPO, PPO, GRPO的原理和区别,写一下DPO loss函数
11. 代码题:lc15 三数之和

### 二面
1. 八股:vLLM中使用的技术是否熟悉(如Paged Attention、KV Cache)?
2. 八股:了解加速推理框架DeepSpeed吗?
3. 八股:MoE模型专家的负载不均衡问题如何解决?
4. 八股:如何通过修改损失函数来解决负载均衡问题?
5. 项目:SFT使用的数据集,使用了多少张卡?SFT训练多久?
6. 项目:SFT 的数据集是越大越好吗?会存在scaling law 吗?
7. 项目:SFT使用的数据可能和原始模型预训练时的数据分布有较大区别,怎么解决?
8. 项目:讲一下LoRA微调的原理,A、B矩阵怎么初始化的,LoRA微调秩设置的是多少
9. 项目:讲一下什么场景下用SFT,什么场景下用RL
10. 项目:为什么使用强化学习会存在训练不稳定问题?为什么业界还在用?
11. 代码题:lc129 求根节点到叶节点数字之和

---

## 案例10:DeepSeek 专项深度面试

### 一面
1. 八股:Transformer的计算复杂度分析,写伪代码
2. 八股:多头和单头的情况下有什么区别
3. 八股:DeepSeek R1的创新点和优化点?
4. 项目:介绍实习经历,并选一篇论文进行讲解
5. 项目:提示工程的主要方法有哪些?有哪些优化技巧?
6. 项目:LLM怎么微调的,数据量多大,各数据配比多少
7. 项目:SFT和强化学习各自有什么优缺点,分别适用于什么场景?
8. 项目:大模型生成内容的评测方式有哪些,具体怎么操作?
9. 项目:大模型输出前后不一致怎么办,如何确保大模型输出内容的一致性?
10. 代码题:手撕sqrt(x),保留6位小数

### 二面
1. 八股:大模型框架了解哪些,介绍下vllm原理
2. 八股:常用的LLM,讲解DeepSeek R1的训练流程和基本原理
3. 八股:讲讲MOE架构和Dense架构差异,在训练和推理方面
4. 项目:介绍实习项目,项目中有没有做微调?
5. 项目:DPO,PPO和GRPO的区别
6. 项目:为什么PPO要用value baseline和GAE?它们如何让训练更稳定?
7. 项目:为什么GRPO在训练MOE时会出问题?原因是啥,怎么改进策略
8. 项目:GRPO的KL散度是什么?KL散度中超参数如何设计?
9. 项目:阐述大模型的幻觉现象及抑制方法
10. 代码题:lc300 最长递增子序列

---

## 案例11:某大厂 Transformer 深度面试

### 一面
1. 八股:Transformer中哪个模块的计算量最大?如何优化
2. 八股:Transformer 的位置编码方式有哪些?RoPE 的核心思想是什么?
3. 八股:在大模型推理阶段,KV Cache 的作用是什么?
4. 项目:在项目中你用过 DPO 吗?和 PPO 相比,它有什么优缺点?
5. 项目:如何在有限算力下做大模型微调?常用方法有哪些?
6. 项目:训练一个7b模型要占用多少显存,不同zero阶段能节省多少显存
7. 项目:如果让 agent 调用搜索引擎,如何避免无关结果影响回答?
8. 项目:你在项目里有没有做过 RAG 里的"召回-过滤-生成"三段式 pipeline?能不能细讲一下?
9. 代码题:lc141 环形链表

### 二面
1. 八股:讲讲transformer架构
2. 八股:Transformer encoder?为什么需要FFN?
3. 八股:LORA和全参数微调的区别
4. 八股:讲DPO,PPO,GRPO
5. 项目:实习项目问的很细,数据构造,微调参数等
6. 项目:Agent整体流程是怎么做的?包括哪些模块
7. 项目:为什么选用deepSeek,了解deepseek-R1吗,介绍一下
8. 项目:Deepseek MLA?为什么压缩?
9. 项目:如果子agent回复不对怎么办?反思?跳不出去怎么办?限制次数
10. 项目:Agent怎么评估效果
11. 代码题:lc143 重排链表

---

## 案例12:综合理论深度面试

### LLM 八股核心问题
1. 请详细解释一下Transformer模型中的自注意力机制是如何工作的?它为什么比 RNN 更适合处理长序列?
2. 什么是位置编码?在Transformer中,为什么它是必需的?请列举至少两种实现方式
3. 请你详细介绍ROPE,对比绝对位置编码它的优劣势分别是什么?
4. 你知道MHA,MQA,GQA的区别吗?详细解释一下
5. 请比较一下几种常见的LLM 架构,例如Encoder-Only, Decoder-Only, 和 Encoder-Decoder,并说明它们各自最擅长的任务类型
6. 什么是Scaling Laws?它揭示了模型性能、计算量和数据量之间的什么关系?这对LLM的研发有什么指导意义?
7. 在LLM的推理阶段,有哪些常见的解码策略?请解释Greedy Search, Beam Search, Top-K Sampling 和Nucleus Sampling (Top-P) 的原理和优缺点
8. 什么是词元化?请比较一下BPE和WordPiece 这两种主流的子词切分算法
9. 你觉得NLP和LLM最大的区别是什么?两者有何共同和不同之处?
10. "涌现能力"是大型模型中一个备受关注的现象,请问你如何理解这个概念?它通常在模型规模达到什么程度时出现?
11. 激活函数有了解吗,你知道哪些LLM常用的激活函数?为什么选用它?
12. 混合专家模型(MoE)是如何在不显著增加推理成本的情况下,有效扩大模型参数规模的?请简述其工作原理
13. 在训练一个百或千亿参数级别的LLM 时,你会面临哪些主要的工程和算法挑战?(例如:显存、通信、训练不稳定性等)
14. 开源框架了解过哪些?Qwen,Deepseek的论文是否有研读过,说一下其中的创新点主要体现在哪?
15. 最近读过哪些LLM比较前沿的论文,聊一下它的相关方法,针对什么问题,提出了什么方法,对比实验有哪些?

---

## 案例13:架构设计与优化深度面试

### 一面
1. 自我介绍
2. 八股:LayerNorm和BatchNorm在训练时梯度计算有何本质区别?
3. 八股:推导MoE架构的负载均衡损失函数,如何避免专家坍缩
4. 八股:多模态融合中 对比学习损失和重构损失如何加权?
5. 八股:解释KV Cache的内存瓶颈 推导多头注意力计算复杂度
6. 项目:微调Qwen时发现验证集loss震荡的可能原因
7. 项目:多工具调用中如何用DAG实现并行调度优化
8. 项目:长文本推理的压缩方案 对比Sliding Window和NTK
9. 项目:模型量化时遇到激活值异常溢出如何调试
10. 项目:自主构建的评估体系里如何分离知识幻觉与推理幻觉
11. 代码题:lc39 组合总和

### 二面
1. 自我介绍
2. 八股:Attention为什么要做scaled,不做会怎么样,为什么用根号 dk
3. 八股:说一下Decoder的因果注意力, QKV分别来自哪
4. 八股:LoRA 初始化怎么做的,用的秩是多少,为什么不选其他的数
5. 项目:agent调用工具不正确怎么办,采用sft或者强化学习怎么来解决
6. 项目:微调过大模型吗?讲一讲
7. 项目:PPO算法为什么有reward model 又有critic model
8. 项目:在使用 GRPO 提升大模型的Function Calling 能力时,除了结果奖励(outcome reward),还可以如何设计过程奖励(process reward)?
9. 场景设计:为智能客服设计多轮对话系统

---

## 案例14:RAG 系统全流程面试

### 一面
1. 介绍RAG项目
2. 怎么解决LLM幻觉问题
3. LLM的参数介绍(temp topk top p等)
4. LLaMA和GLM的区别,模型架构等方面
5. Qwen模型每个版本之间的改进点
6. 介绍检索做的优化,具体追问子问题分解怎么做,有没有做意图识别
7. RAG怎么评估,指标有哪些
8. RAG如果有噪声怎么办
9. 怎么构建SFT数据集,数据量多少,微调方式是什么
10. SFT数据问题不够多样化怎么办
11. 介绍一下function calling和MCP
12. 代码题:lc215 数组中的第 K 个最大元素

### 二面
1. 介绍自己的项目
2. BLEU和ROUGE
3. self-attention求内积时为啥除以根号d
4. LLM的评估
5. 介绍下simCSE
6. 解决tokens不够的问题应该怎么办
7. 详细介绍下deepspeed(三个stage结合参数回答)
8. gpt和llama的区别(模型结构上的)
9. PEFT的方式,LORA论文讲一下,对比p-tuning
10. LLM训练的时候为什么warmup
11. 对比学习中的batch size是大一些好还是小一些好(大一些,甚至可以到10k+,为了构造好的negative样本)
12. 了解最新技术一般怎么通过什么渠道
13. 代码题:lc347 前 K 个高频元素

---

## 案例15:某公司实习项目深挖

### 一面
1. 面试官对实验室的横向项目完全不感兴趣,对前一段实习项目兴趣比较大
2. 详细问了实习项目的细节
3. 之前实习做过用户画像这一块,与现在面试的岗位工作职责有交叉,于是详细问了这一部分是怎么做的
4. Encoder与decoder的中Attention区别?
5. Attention如何计算?为什么除以根号下Dk?mask attention是如何实现的?
6. 除了MHA还知道哪些(GQA MQA MLA)讲原理
7. 为什么要用位置编码?为什么要用sin_cos?
8. 问之前实习的Agent的设计逻辑,问创新方法的实现
9. 问Agent的工具tool的设计,是否是workflow形式
10. 问数据的输入输出格式如何保证大模型输出稳定的json做了哪些工作
11. 代码题:合并两个有序链表

### 二面
1. 简单介绍了项目后,面试官问有什么想跟他分享的于是我详细展开介绍了两个项目
2. 因为实习项目涉及到广告算法,所以问觉得在广告领域用大模型和传统的广告算法相比优缺点是什么
3. 问DPO PPO GRPO DAPO 原理、公式、为什么这么做
4. Deepseek GRPO,讲讲原理和之后的改进
5. 问有没有看过deepseekqwen的技术报告,问MoE
6. Qwen3的技术原理
7. 关于Agent的优缺点和发展前景这一块与面试官一起做了一些讨论
8. 然后详细介绍了他们的业务背景,表示一面面试官对我的评价很好,很希望我能去
9. 代码题:二分查找完全平方数

---

## 案例16:Attention 机制深度剖析

### 一面
1. Transformer中Attention的本质是什么?你能从数学角度简要解释一下吗?
2. 在Agent多轮对话任务中,你觉得Attention的局限性体现在哪些方面?
3. 简要介绍一下SFT的核心流程,以及数据集的构建策略,SFT之后常见的Post-Training还有哪些?它们之间的目的有何区别?
4. 什么是RAG,它是怎么提升生成质量的?与传统检索＋模型生成的流程有何不同?如何评估一个RAG系统是否work的?
5. PPO和DPO在大模型对齐中的主要区别是什么?DPO训练通常有哪些注意事项?用过GRPO么?
6. 项目里的Modular Agent,你能讲讲它是如何实现多步规划的吗?
7. 项目提到了多个工具调用链路,调度策略是如何设计的?是否有异常fallback策略?
8. Agent评估体系包括哪些维度?如何衡量planning能力 vs hallucination rate?
9. 项目里微调Qwen,选择的训练阶段和Loss函数是如何决定的?
10. Prompt自动推荐模块用了哪些优化策略?有没有尝试过Prompt压缩或embedding表示的方式?
11. 场景题:假如一个Agent 推理链路包含3个工具+高频请求,系统整体延迟较高,你会如何优化?
12. 代码:lc 岛屿数量

### 二面
1. 介绍RAG流程;介绍对编码模型的了解、原理、优缺点;如何评估编码模型的能力
2. RAG有哪些分类;多模态RAG有哪些实现框架;伪多模态RAG和多模态RAG分别怎么实现,有什么区别;CLIP可以用于哪一类多模态RAG
3. RAG怎么评估,RAG评估体系中最重要的是什么
4. 传统RAG有什么痛点;介绍GraphRAG,GraphRAG的难点是什么;GraphRAG如何应对增量场景
5. 介绍微调负责的工作;大模型微调最重要的是什么
6. 后训练有哪些方式;微调有哪些方式;LoRA原理及参数量
7. 介绍DPO;DPO与PPO的区别
8. 介绍一些Agent的实现框架;这些框架有什么区别;LangGraph适用于什么场景;LangGraph构建Agent的方式有哪几种

---

## 💡 使用建议

### 如何使用这份面经集锦
1. **第一轮复习**:先学习分类题库(理论、RAG、Agent等),掌握基础知识
2. **第二轮练习**:结合真实面经,模拟完整的面试流程
3. **针对性准备**:根据目标公司,重点练习相应公司的面经

### 面经分析要点
- **高频考点**:Transformer架构、注意力机制、LoRA微调、PPO/DPO/GRPO
- **项目深挖**:务必准备好项目的每个细节,包括数据、模型、优化等
- **编程能力**:LeetCode中等难度题目要熟练掌握
- **系统设计**:Agent系统设计、RAG系统设计是高频考点

### 备考时间规划
- **算法岗**:建议至少准备4-6周,重点在理论推导和项目细节
- **开发岗**:建议至少准备3-4周,重点在系统设计和工程实践
